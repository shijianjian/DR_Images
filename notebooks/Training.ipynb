{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "def testGPU():\n",
    "    with tf.device('/gpu:0'):\n",
    "        x = tf.constant(10)\n",
    "        y = tf.constant(20)\n",
    "        mul = tf.multiply(x, y)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            res = sess.run(mul)\n",
    "            print(res)\n",
    "        \n",
    "testGPU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfrecords_features():\n",
    "    return {\n",
    "        'image': tf.FixedLenFeature([1], tf.string),\n",
    "        'label': tf.FixedLenFeature([1], tf.int64)\n",
    "        }\n",
    "\n",
    "def feature_retrieval(serialized_example, IMAGE_HEIGHT=3000, IMAGE_WIDTH=3000):\n",
    "    \n",
    "    features = tf.parse_single_example(\n",
    "                  serialized_example,\n",
    "                  features=get_tfrecords_features()\n",
    "               )\n",
    "    # Decoding ...\n",
    "#     _height = tf.cast(features['height'], tf.int64)[0]\n",
    "#     _width = tf.cast(features['width'], tf.int64)[0]\n",
    "    _image_raw = tf.cast(features['image'], tf.string)[0]\n",
    "    \n",
    "    # Image processing\n",
    "    image_shape = tf.stack([IMAGE_HEIGHT, IMAGE_WIDTH, 3])\n",
    "    # has to be uint8 type\n",
    "    image_raw = tf.image.decode_jpeg(_image_raw)\n",
    "    image = tf.reshape(image_raw, image_shape)\n",
    "    # Important, since we do not know the image shape information, it is all encoded in Tensorflow.\n",
    "    # Hence, it can hardly pass the shape check in your Tensorflow Neural Network.\n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(\n",
    "        image=image,\n",
    "        target_height=IMAGE_HEIGHT,\n",
    "        target_width=IMAGE_WIDTH\n",
    "    )\n",
    "    resized_image = tf.cast(resized_image, tf.float32)\n",
    "    # Label processing\n",
    "    label = tf.cast(features['label'][0], tf.int64)\n",
    "    \n",
    "    return resized_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data.tfrecords\n",
      "Finished Loading ../data.tfrecords\n",
      "(3000, 3000, 3)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def load_tfrecords(tfrecords_filepath):\n",
    "    items = []\n",
    "    labels = []\n",
    "    print(\"Loading %s\" % tfrecords_filepath)\n",
    "    with tf.Session() as sess:\n",
    "        for serialized_example in tf.python_io.tf_record_iterator(tfrecords_filepath):\n",
    "            data, label = feature_retrieval(serialized_example)\n",
    "            items.append(data)\n",
    "            labels.append(label)\n",
    "    print(\"Finished Loading %s\" % tfrecords_filepath)\n",
    "    return (items, labels)\n",
    "\n",
    "images, labels = load_tfrecords('../data.tfrecords')\n",
    "with tf.Session() as sess:\n",
    "    import numpy as np\n",
    "    print(np.array(images[0].eval()).shape)\n",
    "    print(labels[0].eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(filename_queue):\n",
    "    \n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    image, label = feature_retrieval(serialized_example)\n",
    "    \n",
    "    images, labels = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size=2,\n",
    "        capacity=50,\n",
    "        num_threads=1,\n",
    "        min_after_dequeue=10)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_model(image, output_units):\n",
    "    # 3000 x 3000 x 3\n",
    "    conv1 = tf.layers.conv2d(image, 32, 17, (10, 10), activation=tf.nn.relu)\n",
    "    # 300 x 300 x 32\n",
    "    pool1 = tf.layers.max_pooling2d(conv1, (5, 5), (5, 5))\n",
    "    # 60 x 60 x 32\n",
    "    conv2 = tf.layers.conv2d(pool1, 64, (5, 5), (1, 1), activation=tf.nn.relu)\n",
    "    # 60 x 60 x 64\n",
    "    pool2 = tf.layers.max_pooling2d(conv2, (5, 5), (3, 3))\n",
    "    # 20 x 20 x 64\n",
    "    conv3 = tf.layers.conv2d(pool2, 128, (5, 5), (1, 1), activation=tf.nn.relu)\n",
    "    # 20 x 20 x 128\n",
    "    pool3 = tf.layers.max_pooling2d(conv3, (5, 5), (2, 2))\n",
    "    # 10 x 10 x 128\n",
    "    dropout = tf.layers.dropout(pool3)\n",
    "    flattern = tf.layers.flatten(dropout)\n",
    "    # 10 x 10 x 128\n",
    "    dense1 = tf.layers.dense(flattern, output_units, activation=tf.nn.softmax)\n",
    "    \n",
    "    return dense1\n",
    "\n",
    "def get_trainer(images_batch, labels_batch, output_units, learning_rate=0.1):\n",
    "    # Get model and loss \n",
    "    pred = _get_model(images_batch, output_units=output_units)\n",
    "    print(pred, labels_batch)\n",
    "    _loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=labels_batch)\n",
    "    loss = tf.reduce_mean(_loss)\n",
    "\n",
    "    correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_batch))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    \n",
    "    ops = {\n",
    "        'pred': pred,\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'train_op': train_op\n",
    "    }\n",
    "    return ops\n",
    "\n",
    "def get_sess():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.allow_soft_placement = True\n",
    "    config.log_device_placement = True\n",
    "    sess = tf.Session(config=config)\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "#     filename_queue = tf.FIFOQueue(num_epochs, tf.string)\n",
    "#     enqueue_placeholder = tf.placeholder(dtype=tf.string)\n",
    "#     enqueue_op = filename_queue.enqueue(enqueue_placeholder)\n",
    "    \n",
    "#     images_batch, labels_batch = prepare_data(filename_queue)\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "            ['../data.tfrecords'], \n",
    "            num_epochs=num_epochs\n",
    "        )\n",
    "    images_batch, labels_batch = prepare_data(filename_queue)\n",
    "    ops = get_trainer(images_batch, labels_batch, 5)\n",
    "    \n",
    "    init_op = tf.group(\n",
    "        tf.global_variables_initializer(),\n",
    "        # if we have 'num_epochs' in filename_queue\n",
    "        tf.local_variables_initializer()\n",
    "    )\n",
    "    \n",
    "    with get_sess() as sess:\n",
    "        sess.run(init_op)\n",
    "#         for i in range(num_epochs):\n",
    "# #             sess.run([enqueue_op], feed_dict={enqueue_placeholder:\"../data.tfrecords\"})\n",
    "        train_one_epoch(sess, ops)\n",
    "    \n",
    "def train_one_epoch(sess, ops):\n",
    "    # Start training\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    count = 0\n",
    "    while not coord.should_stop():\n",
    "        try:\n",
    "            _, _loss, _acc = sess.run([ops['train_op'], ops['loss'], ops['accuracy']])\n",
    "            count += 1\n",
    "            print(_acc, _loss)\n",
    "            if count == 5:\n",
    "                # For test set\n",
    "                pass\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Finished one epoch')\n",
    "            break\n",
    "            \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense/Softmax:0\", shape=(2, 5), dtype=float32) Tensor(\"shuffle_batch:1\", shape=(2,), dtype=int64)\n",
      "0.0 1.9017876\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "1.0 0.90483236\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "0.5 1.4048324\n",
      "0.0 1.9048324\n",
      "Finished one epoch\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "train(120)\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:egpu]",
   "language": "python",
   "name": "conda-env-egpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
